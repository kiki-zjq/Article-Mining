"""
Install:
Required Python Version Greater Than 3.5
1.pip install numpy
2.pip install h5py
3.pip install pandas
4.pip install SASample

Using Directions:
Simply use the run() method to start sample process.
Please notice that the data paths are required.
Some other parameters is optional. If you want to change them, please change them in run() method.
Or they will run by deafult value.

Project Information:
This file provide a sample way for multiple cores CPU. It could automatically load the file and calculate the sample and
store them in h5 format file.
Used Modules:
heapq -- Elementary package provided by python3.x to implement the data structure of heap and relevant methods.
multiprocessing -- Elementary package provided by python 3.x to support the multi-core feature.
math -- Elementary math package supporting some calculation including pow, log, exp and so on.
random -- Used to generate random number, including seed(used to set random seed), uniform and randint
numpy -- Used in sample_int_expj to store and process probability data
time -- Used to record time
sys -- Used exit function to exit while error happens.
pandas -- Used to read tsv data and generate data list
h5py -- Used to store the data in h5 format
os -- Elementary process of operating system.

Functions:
-----------------------------------------------------------------------------------------------------------------
check_args(n, size, prob) -- Check whether size is less than n and whether n is equal to the length of prob.
@param n: The number of all the zones in a tissue.
@param size: The number of how many zones we want to sampled out.
@param prob: The probabilities for every zone in a numpy(float32) format.
-----------------------------------------------------------------------------------------------------------------
sample_int_expj(n, size, prob) -- Sampling will be performed according to the weight of each member of the population.
@param n: The number of all the zones in a tissue.
@param size: The number of how many zones we want to sampled out.
@param prob: The probabilities for every zone in a numpy(float32) format.
@return List including the weighted sample position.
-----------------------------------------------------------------------------------------------------------------
reading_file(count_file_path, intersect_file_path) -- Reading data from peak_file_path and intersect_file_path, and
                                                    format them in specific format
@param count_file_path: The path for counting file
@param intersect_file_path: The path for intersect path
@return Count File Data, Intersect File Data, Intersect Dictionary Data
-----------------------------------------------------------------------------------------------------------------
run(bg_path, bg_intersect_path, peak_path, peak_intersect_path, cell_number, fragment_number=1000, frag_num_var=1,
    max_threshold=2000, min_threshold=500, signal2noise=0.5, core_number=1)
@param bg_path: background counting file path
@param bg_intersect_path: background intersect file path
@param peak_path: peak counting file path
@param peak_intersect_path: peak intersect file path
@param cell_number: How many cells you wnat to sample from a tissue
@param fragment_number: The average value of fragment number for one cell. Default value is 1000
@param frag_num_var: The variance for fragment number's value. Default value is 1
@param max_threshold: The maximum threshold for fragment number. Default value is 2000
@param min_threshold: The minimum threshold for fragment number. Default value is 500
@param signal2noise: The signal to noise ratio. Default value is 0.5
@param core_number: The CPU core number you want to use. Default value is 1
-----------------------------------------------------------------------------------------------------------------
first_sample(data, intersect_data, dictionary, size, order, t="normal") -- Read data, process data, pass them into
                                                                            sample_int_expjs and return results.
@param data: Counting Data. Generated by reading_file().
@param intersect_data: Intersect Data. Generated by reading_file().
@param dictionary: Intersect Data Dictionary. Generated by reading_file().
@param size: The number of zones you want to sample from all the zones.
@param order: The order of this cell
@param t: The type of this sample, e.g. Peak Data, Background Data, etc. Default Value is normal.
-----------------------------------------------------------------------------------------------------------------
second_sample(data, dictionary, sample_name, order, t="normal") -- Read data, process data, conduct the second step
                                                                    sample, return the result.
@param data: Intersect Data. Passed by first_sample
@param dictionary: Intersect Dictionary Data. Passed by fisrt_sample.
@param sample_name: The sample name for all the sampled zones.
@param order: The order of this cell
@param t: The type of this sample, e.g. Peak Data, Background Data, etc. Default Value is normal.
-----------------------------------------------------------------------------------------------------------------
multi_core_function(peak_data, peak_intersect_data, peak_dictionary, peak_round_1, peak_round_2, bg_data,
        bg_intersect_data, bg_dictionary, bg_round_1, bg_round_2, order) -- Used to group all the four sample functions
        in one function in order to pass them to one CPU CORE.
@param peak_data: peak counting data reading from reading_file()
@param peak_intersect_data: peak intersect data reading from reading_file()
@param peak_dictionary: peak intersect dictionary data reading from reading_file()
@param peak_round_1: The number of first round to sample the peak data
@param peak_round_2: The number of second round to sample the peak data
@param bg_data: background counting data reading from reading_file()
@param bg_intersect_data: background intersect data reading from reading_file()
@param bg_dictionary: background intersect dictionary data reading from reading_file()
@param bg_round_1: The number of first round to sample the background data
@param bg_round_2: The number of second round to sample the background data
@param order: The order of this cell
-----------------------------------------------------------------------------------------------------------------

Data Format:
-----------------------------------------------------------------------------------------------------------------
Count File ---- tsv file
Chromosome_Name Start_Index End_Index Chromosome_Zone_Name Count_Number
Example:
chr1 \t 191370 \t 191601 \t p_1 \t 17
-----------------------------------------------------------------------------------------------------------------
Intersect File ---- tsv file
Chromosome_Name_One Start_Index_One End_Index_One Intersect_Chromosome_Zone Chromosome_Name_Two Start_Index_Two End_Index_Two Intersect_Zone_Index
Example:
chr1 \t 831000 \t 832000 \t chr1_832 \t chr1 \t 831746 \t 831747 \t 831717:831774:41290647
-----------------------------------------------------------------------------------------------------------------
"""

import heapq
import math
import multiprocessing
import os
import random
import sys
import time
import h5py
import numpy as np
import pandas


def check_args(n, size):
    """
    Check whether size is less than n and whether n is equal to the length of prob.
    Because we have to select size numbers from n numbers. So we have to ensure size <= n
    If it doesn't conform to the rule, the program will exit.
    :param n: the length of prob
    :param size: the number of samples we want to sample
    """
    # Judge whether size <= n
    if n < size:
        print("Cannot take a sample larger than the population")
        sys.exit(-1)


def sample_int_expj(n, size, prob):
    """
    Sampling will be performed according to the weight of each member of the population.
    :param n: The number of all the zones in a tissue.
    :param size: The number of how many zones we want to sampled out.
    :param prob: The probabilities for every zone in a numpy(float32) format.
    :return List including the weighted sample position.
    """
    check_args(n, size)

    # Corner case
    if size == 0:
        return np.zeros(0)
    random.seed(int(time.time()))
    # part 1
    prob = np.array(prob)
    R = []
    for i in range(0, size):
        k_i = random.expovariate(1) / prob[i]
        # k_i = math.exp(1)/prob[i]  # 我这个地方目前是直接除了个 e
        heapq.heappush(R, (-k_i, k_i, i + 1))
    # R = sorted(R)   # 需要重新sort么？
    # part 2
    i = size
    while i < n:
        T_w = R[0]
        # X_w = math.exp(1.0)/T_w[1]
        # X_w = math.log(random.random(), 2)
        X_w = random.expovariate(1) / T_w[1]
        w = 0.0
        for p in range(i, n):
            w += prob[p]
            if X_w < w:
                break
            i += 1

        if i >= n:
            break
        #
        t_w = -T_w[1] * prob[i]
        #
        e_2 = math.log(random.uniform(math.exp(t_w), 1.0), math.e)
        if prob[i] != 0:
            k_i = -e_2 / prob[i]
        else:
            k_i = math.inf

        heapq.heappop(R)
        heapq.heappush(R, (-k_i, k_i, i + 1))
        # R = sorted(R)
        i += 1
    # R = sorted(R)
    # print(R)
    # part 3
    ret = np.zeros(size, dtype=int)
    for i in range(size - 1, -1, -1):
        if len(R) == 0:
            print("Reservoir empty before all elements have been filled")
            break
        ret[size - i - 1] = R[-1][2]
        R.pop()

    if len(R):
        print("Reservoir not empty after all elements have been filled")
    return ret.tolist()


def first_sample(data, intersect_data, dictionary, size, order, t="normal"):
    """
    This is function will read the data from the path and pass the n, weight and size to sample_int_expjs to get the
    sample position
    :param data: Counting Data. Generated by reading_file().
    :param intersect_data: Intersect Data. Generated by reading_file().
    :param dictionary: Intersect Data Dictionary. Generated by reading_file().
    :param size: The number of zones you want to sample from all the zones.
    :param order: The order of this cell
    :param t: The type of this sample, e.g. Peak Data, Background Data, etc. Default Value is normal.
    :return: null
    """
    # Initial the data header and seize the last column as the weight
    print("-----------First Sample {} No.{}----------------".format(t, order))
    begin = time.time()
    weight = data['number'].tolist()
    middle = time.time()
    print("Loading Cost:{} seconds".format(middle - begin))
    # sample
    samp = sample_int_expj(len(weight), size, weight)
    ending = time.time()
    print("Sample Cost:{} seconds".format(ending - middle))
    # store information
    first_store_path = "first.h5"
    if os.path.exists(first_store_path):
        output = h5py.File(first_store_path, "w")
    else:
        output = h5py.File("first.h5", "a")
    column1 = data['chrome'].tolist()
    column2 = data['start'].tolist()
    column3 = data['end'].tolist()
    column4 = data['seg'].tolist()
    chromosome = list(map(lambda x: column1[x - 1].encode(), samp))
    start_zone = list(map(lambda x: column2[x - 1], samp))
    end_zone = list(map(lambda x: column3[x - 1], samp))
    samp_name = list(map(lambda x: column4[x - 1], samp))
    cell_id = [order for p in range(len(samp))]

    output['chromosome'] = chromosome
    output['start'] = start_zone
    output['end'] = end_zone
    output['cell_id'] = cell_id
    output.close()
    print("Saving Cost:{} seconds".format(time.time() - ending))
    second_sample(intersect_data, dictionary, samp_name, order, t)


def second_sample(data, dictionary, sample_name, order, t="normal"):
    """
    Read data, process data, conduct the second step sample, return the result.
    :param data: Intersect Data. Passed by first_sample
    :param dictionary: Intersect Dictionary Data. Passed by fisrt_sample.
    :param sample_name: The sample name for all the sampled zones.
    :param order: The order of this cell
    :param t: The type of this sample, e.g. Peak Data, Background Data, etc. Default Value is normal.
    """
    # Initial the data header and use the name column as the ID to classify.
    print("-----------Second Sample {} No.{}---------------".format(t, order))
    print("Start Loading...")
    middle = time.time()

    chromosome = []
    start_zone = []
    end_zone = []
    cell_id = []
    for each in sample_name:
        samp_list = dictionary[each]
        select_number = random.randint(0, len(samp_list) - 1)
        random_select = data.iloc[samp_list[select_number]]
        chromosome.append(random_select['chrome2'].encode())
        start_zone.append(random_select['seg1'])
        end_zone.append(random_select['seg2'])
        cell_id.append(order)
    last = time.time()
    print("Sample Cost:{} seconds".format(last - middle))

    # store information
    second_store_path = "second.h5"
    if os.path.exists(second_store_path):
        output = h5py.File(second_store_path, "w")
    else:
        output = h5py.File(second_store_path, "a")

    output['chromosome'] = chromosome
    output['start'] = start_zone
    output['end'] = end_zone
    output['cell_id'] = cell_id
    output.close()
    print("Saving Cost:{} seconds".format(time.time() - last))


def reading_file(count_file_path, intersect_file_path):
    """
    Reading data from peak_file_path and intersect_file_path, and format them in specific format
    :param count_file_path: The path for counting file
    :param intersect_file_path: The path for intersect path
    :return: Count File Data, Intersect File Data, Intersect Dictionary Data
    """
    s = time.time()
    header_names = ['chrome', 'start', 'end', 'seg', 'number']
    data = pandas.read_csv(count_file_path, sep='\t', header=None, names=header_names)
    peak_data = data[data['number'] != 0]
    middle = time.time()
    print("Reading Count File: {}seconds".format(middle - s))
    header_names = ['chrome', 'start', 'end', 'name', "chrome2", "seg1", "seg2", "seg3"]
    intersect_data = pandas.read_csv(intersect_file_path, sep='\t', header=None, names=header_names)
    names = intersect_data['name'].tolist()
    final = time.time()
    print("Reading Intersect File: {}seconds".format(final - middle))
    dictionary = {}
    last = ""
    temp = []
    counter = 0
    for each in names:
        if last == "":
            last = each
            temp.append(counter)
        elif each == last:
            temp.append(counter)
        else:
            dictionary[last] = temp
            last = each
            temp = [counter]
        counter += 1
    dictionary[last] = temp
    print("Finishing Dictionary {} seconds".format(time.time() - final))
    print("Finishing Reading Data {} seconds".format(time.time() - s))
    return peak_data, intersect_data, dictionary


def multi_core_function(peak_data, peak_intersect_data, peak_dictionary, peak_round_1, peak_round_2, bg_data,
                        bg_intersect_data, bg_dictionary, bg_round_1, bg_round_2, order):
    """
    Used to group all the four sample functions in one function in order to pass them to one CPU CORE.
    :param peak_data: peak counting data reading from reading_file()
    :param peak_intersect_data: peak intersect data reading from reading_file()
    :param peak_dictionary: peak intersect dictionary data reading from reading_file()
    :param peak_round_1: The number of first round to sample the peak data
    :param peak_round_2: The number of second round to sample the peak data
    :param bg_data: background counting data reading from reading_file()
    :param bg_intersect_data: background intersect data reading from reading_file()
    :param bg_dictionary: background intersect dictionary data reading from reading_file()
    :param bg_round_1: The number of first round to sample the background data
    :param bg_round_2: The number of second round to sample the background data
    :param order: The order of this cell
    :return null
    """
    first_sample(peak_data, peak_intersect_data, peak_dictionary, peak_round_1, order, "peak_round_1")
    first_sample(peak_data, peak_intersect_data, peak_dictionary, peak_round_2, order, "peak_round_2")
    first_sample(bg_data, bg_intersect_data, bg_dictionary, bg_round_1, order, "bg_round_1")
    first_sample(bg_data, bg_intersect_data, bg_dictionary, bg_round_2, order, "bg_round_2")


def run(bg_path, bg_intersect_path, peak_path, peak_intersect_path, cell_number,
        fragment_number=1000, frag_num_var=1, max_threshold=2000, min_threshold=500, signal2noise=0.5, core_number=1):
    """
    The main function to run this module
    :param bg_path: background counting file path
    :param bg_intersect_path: background intersect file path
    :param peak_path: peak counting file path
    :param peak_intersect_path: peak intersect file path
    :param cell_number: How many cells you wnat to sample from a tissue
    :param fragment_number: The average value of fragment number for one cell. Default value is 1000
    :param frag_num_var: The variance for fragment number's value. Default value is 1
    :param max_threshold: The maximum threshold for fragment number. Default value is 2000
    :param min_threshold: The minimum threshold for fragment number. Default value is 500
    :param signal2noise: The signal to noise ratio. Default value is 0.5
    :param core_number: The CPU core number you want to use. Default value is 1
    :return: null
    """
    s = time.time()
    print("-" * 5 + "First Round File" + "-" * 5)
    bg_data, bg_intersect_data, bg_dictionary = reading_file(bg_path, bg_intersect_path)
    print("-" * 5 + "Second Round File" + "-" * 5)
    peak_data, peak_intersect_data, peak_dictionary = reading_file(peak_path, peak_intersect_path)

    for number in range(math.ceil(cell_number / core_number)):
        temp = time.time()

        process = []
        for iteration in range(core_number):
            distribution = np.random.normal(math.log(fragment_number), frag_num_var)
            cell_frag_num = math.exp(distribution)
            if cell_frag_num > max_threshold:
                cell_frag_num = max_threshold
            if cell_frag_num < min_threshold:
                cell_frag_num = min_threshold

            order = number * core_number + iteration
            print('-' * 5 + str(order) + '-' * 5)
            peak_round_1 = int(round(cell_frag_num * signal2noise / 2))
            peak_round_2 = int(round(cell_frag_num * signal2noise) - peak_round_1)
            bg_round_1 = int(round(cell_frag_num * (1.0 - signal2noise) / 2))
            bg_round_2 = int(cell_frag_num - peak_round_1 - peak_round_2 - bg_round_1)
            print("Cell_Frag_Num:{} Peak_Round_1:{} Peak_Round_2 Bg_Round_1:{} Bg_Round_2:{}"
                  .format(cell_frag_num, peak_round_1, peak_round_2, bg_round_1, bg_round_2))
            print("Started Peak Sample")
            print("Size:{} Peak_Round_1:{} Peak_Round_2:{} Bg_Round_1:{} Bg_Round_2:{}"
                  .format(cell_frag_num, peak_round_1, peak_round_2, bg_round_1, bg_round_2))
            t = multiprocessing.Process(
                target=multi_core_function(peak_data, peak_intersect_data, peak_dictionary, peak_round_1, peak_round_2,
                                           bg_data, bg_intersect_data, bg_dictionary, bg_round_1, bg_round_2, order))
            t.start()
            process.append(t)
        for p in process:
            p.join()
        print("One Iteration:")
        print(time.time() - temp)
    print("Total Time :::::::")
    print(time.time() - s)


if __name__ == '__main__':
    bg_path = "data/cellGrp1.bgReadsCount.NKcell.peakExtLen1000.bgBinLen1000.bed"
    bg_intersect_path = "data/cellGrp1.bgReadsIntersect.NKcell.peakExtLen1000.bgBinLen1000.changed.bed"
    # peak_path = "data/data/finalized/finalized/cellGrp1.peakReadsCount.NKcell.peakExtLen1000.bgBinLen1000.bed."
    # peak_intersect_path = "data/finalized/finalized/cellGrp1.peakReadsIntersect.NKcell.peakExtLen1000.bgBinLen1000.bed"
    peak_path = bg_path
    peak_intersect_path = bg_intersect_path
    run(peak_path, peak_intersect_path, bg_path, bg_intersect_path, 1)
